{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "# Constituency Grammars with NLTK"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Objectives\n",
                "- Understanding: \n",
                "    - relation between grammar and syntactic parse tree\n",
                "    - relation between grammar and syntactic categories\n",
                "    - relation between grammar and Part-of-Speech tags\n",
                "    - context free grammars (CFG)\n",
                "    - probabilistic context free grammars (PCFG)\n",
                "- Learning how to:\n",
                "    - define CFG in NLTK\n",
                "    - parse with CFG\n",
                "    - learn PCFGs from a treebank\n",
                "    - parse with PCFG\n",
                "    - generate sentences using a grammar in NLTK\n",
                "    - evaluate parser"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Recommended Reading\n",
                "- Dan Jurafsky and James H. Martin. [__Speech and Language Processing__ (SLP)](https://web.stanford.edu/~jurafsky/slp3/) (3rd ed. draft)\n",
                "- Steven Bird, Ewan Klein, and Edward Loper. [__Natural Language Processing with Python__ (NLTK)](https://www.nltk.org/book/)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Covered Material\n",
                "- SLP\n",
                "    - [Chapter 17: Context-Free Grammars and Constituency Parsing](https://web.stanford.edu/~jurafsky/slp3/17.pdf)\n",
                "- NLTK \n",
                "    - [Chapter 8: Analyzing Sentence Structure](https://www.nltk.org/book/ch08.html)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "source": [
                "### Requirements\n",
                "\n",
                "- [NLTK](https://www.nltk.org/)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Grammars, Production Rules, and Parse Trees"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In linguistics, [**syntax**](https://en.wikipedia.org/wiki/Syntax) is the study of how words and morphemes combine to form larger units such as phrases and sentences. Central concerns of syntax include word order, **grammatical relations**, **hierarchical sentence structure** (constituency), agreement, the nature of crosslinguistic variation, and the relationship between form and meaning."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In linguistics, the [**grammar**](https://en.wikipedia.org/wiki/Grammar) of a natural language is its set of structural constraints on speakers' or writers' composition of clauses, phrases, and words."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A [**context-free grammar (CFG)**](https://en.wikipedia.org/wiki/Context-free_grammar) is a formal grammar whose [**production rules**](https://en.wikipedia.org/wiki/Production_(computer_science)) are of the form:\n",
                "\n",
                "$$A \\to \\alpha$$\n",
                "\n",
                "where: \n",
                "- $A$ a single nonterminal symbol\n",
                "- $\\alpha$  a string of terminals and/or nonterminals"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[**Parsing**](https://en.wikipedia.org/wiki/Parsing), syntax analysis, or syntactic analysis is the process of analyzing a string of symbols, either in natural language, computer languages or data structures, conforming to the rules of a formal grammar. \n",
                "Within computational linguistics the term is used to refer to the formal analysis by a computer of a sentence or other string of words into its **constituents**, resulting in a **parse tree** showing their syntactic relation to each other."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A [**parse tree**](https://en.wikipedia.org/wiki/Parse_tree) or **parsing tree** or **derivation tree** or **concrete syntax tree** is an ordered, rooted tree that represents the syntactic structure of a string according to some **context-free grammar**. The term parse tree itself is used primarily in computational linguistics; in theoretical syntax, the term syntax tree is more common."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1. Parse Tree Representation\n",
                "One of the possible parse trees for a sentence `I saw the man with a telescope` is as below:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "```\n",
                "      S                                    \n",
                "  ____|___________                          \n",
                " |                VP                       \n",
                " |     ___________|________                 \n",
                " |    |       |            PP              \n",
                " |    |       |        ____|___             \n",
                " NP   |       NP      |        NP          \n",
                " |    |    ___|___    |     ___|______      \n",
                "PRON  V  Det      N   P   Det         N    \n",
                " |    |   |       |   |    |          |     \n",
                " I   saw the     man with  a      telescope\n",
                " ```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To occupy less space, a parse tree is usually represented using \"bracketed expressions\", where brackets enclose each **constituent** and the first element of the expression is the tree-node label.\n",
                "\n",
                "```\n",
                "(S\n",
                "  (NP (PRON I))\n",
                "  (VP\n",
                "    (V saw)\n",
                "    (NP (Det the) (N man))\n",
                "    (PP (P with) (NP (Det a) (N telescope)))))\n",
                "```\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It is common to write a parse tree in a less readable one-line expression:\n",
                "\n",
                "```\n",
                "(S (NP (PRON I)) (VP (V saw) (NP (Det the) (N man)) (PP (P with) (NP (Det a) (N telescope)))))\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2. Parse Trees in NLTK"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "NLTK provides `Tree` class for representing hierarchical language structures. The class implements many useful methods. <br> Full documentation [HERE](https://www.nltk.org/api/nltk.tree.tree.html)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 1.2.1. \"Core\" Methods\n",
                "\n",
                "- `fromstring()` reads a bracketed tree string and return the resulting tree\n",
                "\n",
                "- `productions()` generate the productions that correspond to the non-terminal nodes of the tree.\n",
                "    - For each subtree of the form `(P: C1 C2 ... Cn)` this produces a production of the form `P -> C1 C2 ... Cn`.\n",
                "\n",
                "- `label()` returns the node label of the tree\n",
                "\n",
                "- `subtrees()` generates all the subtrees of this tree\n",
                "\n",
                "- `pos()` return a sequence of pos-tagged words extracted from the tree.\n",
                "\n",
                "- `leaves()` returns the leaves of the tree.\n",
                "\n",
                "- `flatten()` return a flat version of the tree, with all non-root non-terminals removed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [],
            "source": [
                "from nltk.tree import Tree\n",
                "sent = \"I saw the man with a telescope\"\n",
                "parse_tree_str = \"(S (NP (PRON I)) (VP (V saw) (NP (Det the) (N man)) (PP (P with) (NP (Det a) (N telescope)))))\"\n",
                "\n",
                "tree = Tree.fromstring(parse_tree_str)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(S\n",
                        "  (NP (PRON I))\n",
                        "  (VP\n",
                        "    (V saw)\n",
                        "    (NP (Det the) (N man))\n",
                        "    (PP (P with) (NP (Det a) (N telescope)))))\n"
                    ]
                }
            ],
            "source": [
                "# prints bracketed expression for the parse tree\n",
                "print(tree) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "-----------------------------------------------------------------------------------------\n",
                        "(S\n",
                        "  (NP (PRON I))\n",
                        "  (VP\n",
                        "    (V saw)\n",
                        "    (NP (Det the) (N man))\n",
                        "    (PP (P with) (NP (Det a) (N telescope)))))\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(NP (PRON I))\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(PRON I)\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(VP\n",
                        "  (V saw)\n",
                        "  (NP (Det the) (N man))\n",
                        "  (PP (P with) (NP (Det a) (N telescope))))\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(V saw)\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(NP (Det the) (N man))\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(Det the)\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(N man)\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(PP (P with) (NP (Det a) (N telescope)))\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(P with)\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(NP (Det a) (N telescope))\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(Det a)\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "(N telescope)\n"
                    ]
                }
            ],
            "source": [
                "# prints all the subtrees\n",
                "for stree in tree.subtrees():\n",
                "    print('-'*89)\n",
                "    print(stree)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 1.2.2 Visualizaing Parse Trees\n",
                "\n",
                "In the code above, we have printed the parse tree using `print()` method, which prints a _bracketed expression_ tree.\n",
                "It is also possible to visualize syntactic trees of using other method: \n",
                "\n",
                "- `pprint()` the same as above\n",
                "- `pretty_print()` draws ASCII tree (the original example)\n",
                "- `draw()` opens a new window containing a graphical diagram of this tree.\n",
                "- `tree` a call to a tree draws it using `svgling` \n",
                "    - requires `svgling` module to be installed (`pip install svgling`)\n",
                "    - GitHub https://github.com/rawlins/svgling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "         S                                                         \n",
                        " ┌───────┴────────────────────┐                                        \n",
                        " │                            VP                                   \n",
                        " │       ┌─────────────┬──────┴──────────────┐                         \n",
                        " │       │             │                     PP                    \n",
                        " │       │             │             ┌───────┴──────┐                  \n",
                        " NP      │             NP            │              NP             \n",
                        " │       │      ┌──────┴──────┐      │       ┌──────┴─────────┐        \n",
                        "PRON     V     Det            N      P      Det               N    \n",
                        " │       │      │             │      │       │                │        \n",
                        " I      saw    the           man    with     a            telescope\n",
                        "\n",
                        "None\n"
                    ]
                }
            ],
            "source": [
                "tree\n",
                "print(tree.pretty_print(unicodelines=True, nodedist=4))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(S\n",
                        "  (NP (PRON I))\n",
                        "  (VP\n",
                        "    (V saw)\n",
                        "    (NP (Det the) (N man))\n",
                        "    (PP (P with) (NP (Det a) (N telescope)))))\n",
                        "None\n",
                        "      S                                    \n",
                        "  ____|___________                          \n",
                        " |                VP                       \n",
                        " |     ___________|________                 \n",
                        " |    |       |            PP              \n",
                        " |    |       |        ____|___             \n",
                        " NP   |       NP      |        NP          \n",
                        " |    |    ___|___    |     ___|______      \n",
                        "PRON  V  Det      N   P   Det         N    \n",
                        " |    |   |       |   |    |          |     \n",
                        " I   saw the     man with  a      telescope\n",
                        "\n",
                        "None\n",
                        "         S                                                         \n",
                        " ┌───────┴────────────────────┐                                        \n",
                        " │                            VP                                   \n",
                        " │       ┌─────────────┬──────┴──────────────┐                         \n",
                        " │       │             │                     PP                    \n",
                        " │       │             │             ┌───────┴──────┐                  \n",
                        " NP      │             NP            │              NP             \n",
                        " │       │      ┌──────┴──────┐      │       ┌──────┴─────────┐        \n",
                        "PRON     V     Det            N      P      Det               N    \n",
                        " │       │      │             │      │       │                │        \n",
                        " I      saw    the           man    with     a            telescope\n",
                        "\n",
                        "None\n"
                    ]
                }
            ],
            "source": [
                "from pprint import pprint\n",
                "print(tree.pprint())\n",
                "print(tree.pretty_print()) # or\n",
                "print(tree.pretty_print(unicodelines=True, nodedist=4)) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [],
            "source": [
                "tree.draw()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Exercise\n",
                "Familiarize with the [`Tree`](https://www.nltk.org/api/nltk.tree.tree.html) class.\n",
                "\n",
                "- Consult the documentation for more detail (and other methods)\n",
                "- Try each of the \"core\" methods listed above\n",
                "    - see production rules, leaves, and pos\n",
                "\n",
                "######   \"Core\" Methods\n",
                "\n",
                "- `fromstring()` reads a bracketed tree string and return the resulting tree\n",
                "\n",
                "- `productions()` generate the productions that correspond to the non-terminal nodes of the tree.\n",
                "    - For each subtree of the form `(P: C1 C2 ... Cn)` this produces a production of the form `P -> C1 C2 ... Cn`.\n",
                "\n",
                "- `label()` returns the node label of the tree\n",
                "\n",
                "- `subtrees()` generates all the subtrees of this tree\n",
                "\n",
                "- `pos()` return a sequence of pos-tagged words extracted from the tree.\n",
                "\n",
                "- `leaves()` returns the leaves of the tree.\n",
                "\n",
                "- `flatten()` return a flat version of the tree, with all non-root non-terminals removed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Productions:\n",
                        "[S -> NP VP,\n",
                        " NP -> PRON,\n",
                        " PRON -> 'I',\n",
                        " VP -> V NP PP,\n",
                        " V -> 'saw',\n",
                        " NP -> Det N,\n",
                        " Det -> 'the',\n",
                        " N -> 'man',\n",
                        " PP -> P NP,\n",
                        " P -> 'with',\n",
                        " NP -> Det N,\n",
                        " Det -> 'a',\n",
                        " N -> 'telescope']\n",
                        "Label: VP\n",
                        "Pos Tags: [('I', 'PRON'), ('saw', 'V'), ('the', 'Det'), ('man', 'N'), ('with', 'P'), ('a', 'Det'), ('telescope', 'N')]\n",
                        "Leaves: ['I', 'saw', 'the', 'man', 'with', 'a', 'telescope']\n",
                        "Flatten: (S I saw the man with a telescope)\n"
                    ]
                }
            ],
            "source": [
                "parse_tree_str = \"(S (NP (PRON I)) (VP (V saw) (NP (Det the) (N man)) (PP (P with) (NP (Det a) (N telescope)))))\"\n",
                "tree = Tree.fromstring(parse_tree_str)\n",
                "\n",
                "# Productions\n",
                "print('Productions:')\n",
                "pprint(tree.productions())\n",
                "\n",
                "# Label\n",
                "print('Label:',tree[1].label() )\n",
                "\n",
                "# Pos tags\n",
                "print('Pos Tags:', tree.pos())\n",
                "\n",
                "# Leaves \n",
                "print('Leaves:', tree.leaves())\n",
                "\n",
                "# Flatten\n",
                "print('Flatten:', tree.flatten())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Context Free Grammars (CFG)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### 2.1. Defining Context Free Grammars\n",
                "\n",
                "CFG are defined by a *start symbol* and a set of *production rules*. The *start symbol* defines the root node of parse trees (usually __S__). \n",
                "\n",
                "*Production rules* specify allowed parent-child relations in a parse tree. Each production specifies what node can be the parent of a particular set of children nodes. \n",
                "\n",
                "For example, the production `S -> NP VP` specifies that an `S` node can be the parent of an `NP` node and a `VP` node.\n",
                "\n",
                "The left-hand side of a production rules specifies potential *non-terminal* parent nodes; while right-hand side specifies list of allowed *non-terminal* and *terminal* (text) children. \n",
                "\n",
                "A production like `VP -> V NP | VP PP` has a disjunction on the right-hand side, shown by the `|` and is an abbreviation for the two productions `VP -> V NP` and `VP -> V NP PP`.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "#### 2.1.1 Syntactic Categories\n",
                "\n",
                "| __Symbol__ | __Meaning__ | __Example__ |\n",
                "|:-----------|:------------|:------------|\n",
                "| S   | sentence             | I saw the man |\n",
                "| NP  | noun phrase          | the man | \n",
                "| VP  | verb phrase          | saw the man |\n",
                "| PP  | prepositional phrase | with a telescope |\n",
                "| Det | determiner  | the |\n",
                "| N   | noun        | man |\n",
                "| V   | verb        | saw |\n",
                "| P   | preposition | with |\n",
                "\n",
                "\n",
                "- Non-Terminals: `S`, `NP`, `VP`, `PP`\n",
                "- Pre-Terminals: `Det`, `N`, `V`, `P` (Part-of-Speech Tags)\n",
                "- Terminals (Leaves): the, man, saw, ..."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### 2.2. Defining Context Free Grammars in NLTK\n",
                "\n",
                "The grammar can be defined as a string or as a list of strings of production rules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Grammar with 14 productions (start state = S)\n",
                        "    S -> NP VP\n",
                        "    NP -> Det N\n",
                        "    NP -> Det N PP\n",
                        "    NP -> PRON\n",
                        "    VP -> V NP\n",
                        "    VP -> V NP PP\n",
                        "    PP -> P NP\n",
                        "    Det -> 'the'\n",
                        "    Det -> 'a'\n",
                        "    N -> 'man'\n",
                        "    N -> 'telescope'\n",
                        "    PRON -> 'I'\n",
                        "    V -> 'saw'\n",
                        "    P -> 'with'\n"
                    ]
                }
            ],
            "source": [
                "import nltk\n",
                "\n",
                "rules = [\n",
                "    'S -> NP VP',\n",
                "    'NP -> Det N | Det N PP | PRON',\n",
                "    'VP -> V NP | V NP PP',\n",
                "    'PP -> P NP',\n",
                "    'Det -> \"the\" | \"a\"',\n",
                "    'N -> \"man\" | \"telescope\"',\n",
                "    'PRON -> \"I\"',\n",
                "    'V -> \"saw\"',\n",
                "    'P -> \"with\"'   \n",
                "]\n",
                "\n",
                "toy_grammar = nltk.CFG.fromstring(rules)\n",
                "\n",
                "print(toy_grammar)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "Grammar object has 2 components:\n",
                "- start symbol\n",
                "- production rules\n",
                "\n",
                "Those can be access as follows."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {
                "scrolled": true,
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "S\n"
                    ]
                }
            ],
            "source": [
                "print(toy_grammar.start())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[S -> NP VP, NP -> Det N, NP -> Det N PP, NP -> PRON, VP -> V NP, VP -> V NP PP, PP -> P NP, Det -> 'the', Det -> 'a', N -> 'man', N -> 'telescope', PRON -> 'I', V -> 'saw', P -> 'with']\n"
                    ]
                }
            ],
            "source": [
                "print(toy_grammar.productions())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "Each production has 2 parts:\n",
                "- left-hand side\n",
                "- right-hand side\n",
                "\n",
                "which can be accessed as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {
                "scrolled": true,
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "S\n",
                        "(NP, VP)\n"
                    ]
                }
            ],
            "source": [
                "rule = toy_grammar.productions()[0]\n",
                "print(rule.lhs())\n",
                "print(rule.rhs())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "__Grammar__'s `productions(lhs=None, rhs=None, empty=False)` methos returns the grammar productions, filtered by the left-hand side or the first item in the right-hand side.\n",
                "\n",
                "__Parameters__\n",
                "- `lhs` -- Only return productions with the given left-hand side.\n",
                "- `rhs` -- Only return productions with the given first item in the right-hand side.\n",
                "- `empty` -- Only return productions with an empty right-hand side"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[NP -> Det N, NP -> Det N PP, NP -> PRON]"
                        ]
                    },
                    "execution_count": 68,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from nltk import Nonterminal\n",
                "toy_grammar.productions(lhs=Nonterminal('NP'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[S -> NP VP]"
                        ]
                    },
                    "execution_count": 69,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "toy_grammar.productions(rhs=Nonterminal('NP'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "dict_values([])"
                        ]
                    },
                    "execution_count": 70,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "toy_grammar.productions(empty=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### 2.3. Parsing with CFG\n",
                "\n",
                "> A parser processes input sentences according to the productions of a grammar, and builds one or more constituent structures that conform to the grammar. A grammar is a declarative specification of well-formedness — it is actually just a string, not a program. A parser is a procedural interpretation of the grammar. It searches through the space of trees licensed by a grammar to find one that has the required sentence along its fringe (outer edges).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "#### 2.3.1. Available CFG Parsers in NLTK\n",
                "\n",
                "- Recursive descent parsing\n",
                "    - top-down algorithm\n",
                "    - pro: finds all successful parses.\n",
                "    - con: inefficient. will try all rules brute-force, even the ones that do not match the input. Goes into an infinite loop when handling a left-recursive rule.\n",
                "    - `nltk.RecursiveDescentParser()`\n",
                "\n",
                "- Shift-reduce parsing\n",
                "    - bottom-up algorithm\n",
                "    - pro: efficient. only works with the rules that match input words.\n",
                "    - con: may fail to find a legitimate parse even when there is one.\n",
                "    - `nltk.ShiftReduceParser()`\n",
                "\n",
                "- The left-corner parser\n",
                "    - a top-down parser with bottom-up filtering\n",
                "    - `nltk.LeftCornerChartParser()`: combines left-corner parsing and chart parsing\n",
                "\n",
                "- Chart parsing\n",
                "    - utilizes dynamic programming: builds and refers to well-formed substring tables (WFST)\n",
                "    - pro: efficient.\n",
                "    - con: may take up a big memory space when dealing with a long sentence.\n",
                "    - `nltk.ChartParser()`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "Unable to parse line 3: NP -> Det N PP,VP -> V NP | V NP PP\nExpected a nonterminal, found: ,VP -> V NP | V NP PP",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "File \u001b[1;32mc:\\Users\\maxst\\miniconda3\\envs\\NLU\\lib\\site-packages\\nltk\\grammar.py:1435\u001b[0m, in \u001b[0;36mread_grammar\u001b[1;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[0;32m   1433\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m         \u001b[39m# expand out the disjunctions on the RHS\u001b[39;00m\n\u001b[1;32m-> 1435\u001b[0m         productions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _read_production(line, nonterm_parser, probabilistic)\n\u001b[0;32m   1436\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
                        "File \u001b[1;32mc:\\Users\\maxst\\miniconda3\\envs\\NLU\\lib\\site-packages\\nltk\\grammar.py:1374\u001b[0m, in \u001b[0;36m_read_production\u001b[1;34m(line, nonterm_parser, probabilistic)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39m# Anything else -- nonterminal.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m     nonterm, pos \u001b[39m=\u001b[39m nonterm_parser(line, pos)\n\u001b[0;32m   1375\u001b[0m     rhsides[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mappend(nonterm)\n",
                        "File \u001b[1;32mc:\\Users\\maxst\\miniconda3\\envs\\NLU\\lib\\site-packages\\nltk\\grammar.py:1452\u001b[0m, in \u001b[0;36mstandard_nonterm_parser\u001b[1;34m(string, pos)\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m m:\n\u001b[1;32m-> 1452\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected a nonterminal, found: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m string[pos:])\n\u001b[0;32m   1453\u001b[0m \u001b[39mreturn\u001b[39;00m (Nonterminal(m\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m)), m\u001b[39m.\u001b[39mend())\n",
                        "\u001b[1;31mValueError\u001b[0m: Expected a nonterminal, found: ,VP -> V NP | V NP PP",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[71], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m rules \u001b[39m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mS -> NP VP\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mNP -> Det N | PRON \u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mP -> \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwith\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m   \n\u001b[0;32m     12\u001b[0m ]\n\u001b[1;32m---> 14\u001b[0m toy_grammar \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mCFG\u001b[39m.\u001b[39;49mfromstring(rules)\n",
                        "File \u001b[1;32mc:\\Users\\maxst\\miniconda3\\envs\\NLU\\lib\\site-packages\\nltk\\grammar.py:547\u001b[0m, in \u001b[0;36mCFG.fromstring\u001b[1;34m(cls, input, encoding)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    541\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfromstring\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39minput\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    542\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[39m    Return the grammar instance corresponding to the input string(s).\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \n\u001b[0;32m    545\u001b[0m \u001b[39m    :param input: a grammar, either in the form of a string or as a list of strings.\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 547\u001b[0m     start, productions \u001b[39m=\u001b[39m read_grammar(\n\u001b[0;32m    548\u001b[0m         \u001b[39minput\u001b[39;49m, standard_nonterm_parser, encoding\u001b[39m=\u001b[39;49mencoding\n\u001b[0;32m    549\u001b[0m     )\n\u001b[0;32m    550\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(start, productions)\n",
                        "File \u001b[1;32mc:\\Users\\maxst\\miniconda3\\envs\\NLU\\lib\\site-packages\\nltk\\grammar.py:1437\u001b[0m, in \u001b[0;36mread_grammar\u001b[1;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[0;32m   1435\u001b[0m             productions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _read_production(line, nonterm_parser, probabilistic)\n\u001b[0;32m   1436\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1437\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to parse line \u001b[39m\u001b[39m{\u001b[39;00mlinenum\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mline\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m productions:\n\u001b[0;32m   1440\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo productions found!\u001b[39m\u001b[39m\"\u001b[39m)\n",
                        "\u001b[1;31mValueError\u001b[0m: Unable to parse line 3: NP -> Det N PP,VP -> V NP | V NP PP\nExpected a nonterminal, found: ,VP -> V NP | V NP PP"
                    ]
                }
            ],
            "source": [
                "rules = [\n",
                "    'S -> NP VP',\n",
                "    'NP -> Det N | PRON ',\n",
                "    'NP -> Det N PP,'\n",
                "    'VP -> V NP | V NP PP',\n",
                "    'PP -> P NP',\n",
                "    'Det -> \"the\" | \"a\"',\n",
                "    'N -> \"man\" | \"telescope\"',\n",
                "    'PRON -> \"I\"',\n",
                "    'V -> \"saw\"',\n",
                "    'P -> \"with\"'   \n",
                "]\n",
                "\n",
                "toy_grammar = nltk.CFG.fromstring(rules)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true,
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(S\n",
                        "  (NP (PRON I))\n",
                        "  (VP\n",
                        "    (V saw)\n",
                        "    (NP (Det the) (N man))\n",
                        "    (PP (P with) (NP (Det a) (N telescope)))))\n",
                        "(S\n",
                        "  (NP (PRON I))\n",
                        "  (VP\n",
                        "    (V saw)\n",
                        "    (NP (Det the) (N man) (PP (P with) (NP (Det a) (N telescope))))))\n"
                    ]
                }
            ],
            "source": [
                "parser = nltk.ChartParser(toy_grammar)\n",
                "\n",
                "sent = \"I saw the man with a telescope\"\n",
                "\n",
                "for tree in parser.parse(sent.split()):\n",
                "    print(tree)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "source": [
                "The sentence produces two possible parse trees. Thus, it is said to be structurally ambiguous -- prepositional phrase attachment ambiguity."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "#### Exercise\n",
                "\n",
                "- Define grammar that covers the following sentences.\n",
                "\n",
                "    - show flights from new york to los angeles\n",
                "    - list flights from new york to los angeles\n",
                "    - show flights from new york\n",
                "    - list flights to los angeles\n",
                "    - list flights\n",
                "- Use one of the parsers to parse the sentences (i.e. test your grammar)\n",
                "\n",
                "**Note:** <br>\n",
                "- start from Verb Pharse\n",
                "- Prepositional Phrase (PP) are composed of a preposition and a Noun Phrase \n",
                "- 'los' and 'angeles' are two consecutive nouns (N) (same for new york)\n",
                "\n",
                "#### Useful reminder from above\n",
                "\n",
                "\n",
                "| __Symbol__ | __Meaning__ | __Example__ |\n",
                "|:-----------|:------------|:------------|\n",
                "| S   | sentence             | I saw the man |\n",
                "| NP  | noun phrase          | the man | \n",
                "| VP  | verb phrase          | saw the man |\n",
                "| PP  | prepositional phrase | with a telescope |\n",
                "| Det | determiner  | the |\n",
                "| N   | noun        | man |\n",
                "| V   | verb        | saw |\n",
                "| P   | preposition | with |\n",
                "\n",
                "\n",
                "- Non-Terminals: `S`, `NP`, `VP`, `PP`\n",
                "- Pre-Terminals: `Det`, `N`, `V`, `P` (Part-of-Speech Tags)\n",
                "- Terminals (Leaves): the, man, saw, ...\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "slideshow": {
                    "slide_type": "skip"
                }
            },
            "outputs": [],
            "source": [
                "# test setenteces\n",
                "test_sents = [\n",
                "    \"show flights from new york to los angeles\", \n",
                "    \"list flights from new york to los angeles\",\n",
                "    \"show flights from new york\",\n",
                "    \"list flights to los angeles\",\n",
                "    \"list flights\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rules = [\n",
                "    'S -> VP | VP PP | VP PP PP',\n",
                "    'VP -> V NP',\n",
                "    'NP -> N | N N',\n",
                "    'PP -> P NP',\n",
                "    'P -> \"from\" | \"to\"',\n",
                "    'N -> \"los\" | \"angeles\" | \"new\" | \"york\" | \"flights\"' ,\n",
                "    'V -> \"show\" | \"list\"' \n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "show flights from new york to los angeles\n",
                        "(S\n",
                        "  (VP (V show) (NP (N flights)))\n",
                        "  (PP (P from) (NP (N new) (N york)))\n",
                        "  (PP (P to) (NP (N los) (N angeles))))\n",
                        "None\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "list flights from new york to los angeles\n",
                        "(S\n",
                        "  (VP (V list) (NP (N flights)))\n",
                        "  (PP (P from) (NP (N new) (N york)))\n",
                        "  (PP (P to) (NP (N los) (N angeles))))\n",
                        "None\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "show flights from new york\n",
                        "(S\n",
                        "  (VP (V show) (NP (N flights)))\n",
                        "  (PP (P from) (NP (N new) (N york))))\n",
                        "None\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "list flights to los angeles\n",
                        "(S\n",
                        "  (VP (V list) (NP (N flights)))\n",
                        "  (PP (P to) (NP (N los) (N angeles))))\n",
                        "None\n",
                        "-----------------------------------------------------------------------------------------\n",
                        "list flights\n",
                        "(S (VP (V list) (NP (N flights))))\n",
                        "None\n",
                        "-----------------------------------------------------------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "toy_grammar = nltk.CFG.fromstring(rules)\n",
                "parser = nltk.ChartParser(toy_grammar)\n",
                "for sent in test_sents:\n",
                "    print(sent)\n",
                "    for tree in parser.parse(sent.split()):\n",
                "        print(tree.pprint())\n",
                "    print('-'*89)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3.2. \"Real\" Grammars"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It is possible to load a grammar written by someone else into NLTK.\n",
                "\n",
                "- run `nltk.download()`\n",
                "- go to `Models` tab\n",
                "- download `large_grammars`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package large_grammars to\n",
                        "[nltk_data]     C:\\Users\\maxst\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Unzipping grammars\\large_grammars.zip.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 105,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nltk.download('large_grammars')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "atis_grammar = nltk.data.load('grammars/large_grammars/atis.cfg')\n",
                "atis_parser = nltk.ChartParser(atis_grammar)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<Grammar with 5517 productions>"
                        ]
                    },
                    "execution_count": 107,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "atis_grammar"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The grammar comes with some test sentences."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(['i', 'need', 'a', 'flight', 'from', 'charlotte', 'to', 'las', 'vegas', 'that', 'makes', 'a', 'stop', 'in', 'saint', 'louis', '.'], 2085)\n"
                    ]
                }
            ],
            "source": [
                "atis_test_sentences = nltk.data.load('grammars/large_grammars/atis_sentences.txt')\n",
                "atis_test_sentences = nltk.parse.util.extract_test_sentences(atis_test_sentences)\n",
                "print(atis_test_sentences[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Each test sentence is a tuple of a list of sentence words and a number of possible parses with respect to the grammar."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2085 2085\n",
                        "1380 1380\n",
                        "50 50\n"
                    ]
                }
            ],
            "source": [
                "# let's check the number of parses our parser produces\n",
                "for sent, pnum in atis_test_sentences[:3]:\n",
                "    parses = atis_parser.parse(sent)\n",
                "    print(len(list(parses)), pnum)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Exercise\n",
                "Parse the sentences from the excercise above using **ATIS_GRAMMAR**\n",
                "- try different parsers\n",
                "- output the number of parses each sentence yields "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "3\n",
                        "3\n",
                        "1\n",
                        "1\n",
                        "1\n"
                    ]
                }
            ],
            "source": [
                "atis_parser = nltk.LeftCornerChartParser(atis_grammar) # Add your parser\n",
                "for sent in test_sents:\n",
                "    parses = atis_parser.parse(sent.split())\n",
                "    print(len(list(parses)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "## 3. Probabilistic Context Free Grammars (PCFG)\n",
                "\n",
                "PCFGs are very similar to CFGs - they just have an additional probability for each production. \n",
                "\n",
                "For a given left-hand-side non-terminal, the sum of the probabilities must be 1.0!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Grammar with 14 productions (start state = S)\n",
                        "    S -> NP VP [1.0]\n",
                        "    NP -> Det N [0.6]\n",
                        "    NP -> Det N PP [0.3]\n",
                        "    NP -> PRON [0.1]\n",
                        "    VP -> V NP [0.7]\n",
                        "    VP -> V NP PP [0.3]\n",
                        "    PP -> P NP [1.0]\n",
                        "    Det -> 'the' [0.5]\n",
                        "    Det -> 'a' [0.5]\n",
                        "    N -> 'man' [0.5]\n",
                        "    N -> 'telescope' [0.5]\n",
                        "    PRON -> 'I' [1.0]\n",
                        "    V -> 'saw' [1.0]\n",
                        "    P -> 'with' [1.0]\n"
                    ]
                }
            ],
            "source": [
                "weighted_rules = [\n",
                "    'S -> NP VP [1.0]',\n",
                "    'NP -> Det N [0.6]',\n",
                "    'NP -> Det N PP [0.3]',\n",
                "    'NP -> PRON [0.1]',\n",
                "    'VP -> V NP [0.7]',\n",
                "    'VP -> V NP PP [0.3]',\n",
                "    'PP -> P NP [1.0]',\n",
                "    'Det -> \"the\" [0.5]',\n",
                "    'Det -> \"a\" [0.5]',\n",
                "    'N -> \"man\" [0.5]',\n",
                "    'N -> \"telescope\" [0.5]',\n",
                "    'PRON -> \"I\" [1.0]',\n",
                "    'V -> \"saw\" [1.0]',\n",
                "    'P -> \"with\" [1.0]'   \n",
                "]\n",
                "\n",
                "toy_grammar = nltk.PCFG.fromstring(weighted_rules)\n",
                "\n",
                "print(toy_grammar)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "On top of right-hand side and left-hand side, probabilistic rules have probabilities."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "S\n",
                        "(NP, VP)\n",
                        "1.0\n"
                    ]
                }
            ],
            "source": [
                "rule = toy_grammar.productions()[2]\n",
                "print(rule.lhs())\n",
                "print(rule.rhs())\n",
                "print(rule.prob())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### 3.1. Learning Grammars from a Treebank\n",
                "\n",
                "The most important method consists of inducing a PCFG from trees in a treebank (`induce_pcfg()`). \n",
                "\n",
                "NLTK provides portion of Penn Treebank corpus, which we can utilize to induce rules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package treebank to\n",
                        "[nltk_data]     C:\\Users\\maxst\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package treebank is already up-to-date!\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 114,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nltk.download('treebank')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "Production rules can be extracted using `productions()` method iterating over parsed sentences in the corpus."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<BracketParseCorpusReader in '.../corpora/treebank/combined' (not loaded yet)>\n",
                        "179360\n"
                    ]
                }
            ],
            "source": [
                "from nltk.corpus import treebank\n",
                "\n",
                "print(treebank)\n",
                "\n",
                "productions = []\n",
                "# let's keep it small\n",
                "for item in treebank.fileids():\n",
                "    for tree in treebank.parsed_sents(item):\n",
                "        productions += tree.productions()\n",
                "    \n",
                "print(len(productions))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "The grammar can be induced as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [],
            "source": [
                "from nltk import Nonterminal\n",
                "S = Nonterminal('S')\n",
                "grammar = nltk.induce_pcfg(S, productions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "S -> NP-SBJ VP . [0.162428]"
                        ]
                    },
                    "execution_count": 76,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "grammar\n",
                "grammar.productions()[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### 3.2. PCFG Parsers in NLTK\n",
                "NLTK provides several PCFG parsers:\n",
                "\n",
                "From `nltk.parse.viterbi`\n",
                "\n",
                "- ViterbiParser\n",
                "    - A bottom-up PCFG parser that uses dynamic programming to find the single most likely parse for a text. The ViterbiParser parser parses texts by filling in a “most likely constituent table”. This table records the most probable tree representation for any given span and node value. In particular, it has an entry for every start index, end index, and node value, recording the most likely subtree that spans from the start index to the end index, and has the given node value.\n",
                "\n",
                "From `nltk.parse.pchart` module\n",
                "\n",
                "- InsideChartParser\n",
                "    - A bottom-up parser for PCFG grammars that tries edges in descending order of the inside probabilities of their trees.\n",
                "    - use `beam_size = len(tokens)+1` argument\n",
                "    \n",
                "- RandomChartParser\n",
                "    - A bottom-up parser for PCFG grammars that tries edges in random order. This sorting order results in a random search strategy.\n",
                "    \n",
                "- UnsortedChartParser\n",
                "    - A bottom-up parser for PCFG grammars that tries edges in whatever order.\n",
                "\n",
                "- LongestChartParser\n",
                "    - A bottom-up parser for PCFG grammars that tries longer edges before shorter ones. This sorting order results in a type of best-first search strategy.\n",
                "\n",
                "Read about them in the [documentation](http://www.nltk.org/api/nltk.parse.html)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "Let's parse one of the sentences from above using Viterbi parser."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(S\n",
                        "  (NP-SBJ (NNP Show))\n",
                        "  (NP-PRD\n",
                        "    (NP (NP (PRP me)) (NNS flights))\n",
                        "    (PP\n",
                        "      (IN from)\n",
                        "      (NP\n",
                        "        (NP (NNP New) (NNP York))\n",
                        "        (PP (TO to) (NP (NNP Los) (NNP Angeles))))))) (p=1.23346e-35)\n"
                    ]
                }
            ],
            "source": [
                "parser = nltk.ViterbiParser(grammar)\n",
                "for tree in parser.parse(\"Show me flights from New York to Los Angeles\".split()):\n",
                "    print(tree)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "### Exercise\n",
                "\n",
                "- Try different parser to parse the sentences from the exercises above\n",
                "- Compare assigned probabilities\n",
                "- Compare time it takes to parse sentences"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenized_sentence = \"show me flights from New York to Los Angeles\".split()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {
                "slideshow": {
                    "slide_type": "skip"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(S\n",
                        "  (NP-SBJ (NN show))\n",
                        "  (NP-PRD\n",
                        "    (NP (NP (PRP me)) (NNS flights))\n",
                        "    (PP\n",
                        "      (IN from)\n",
                        "      (NP\n",
                        "        (NP (NNP New) (NNP York))\n",
                        "        (PP (TO to) (NP (NNP Los) (NNP Angeles))))))) (p=2.0478e-35)\n",
                        "CPU times: total: 9.77 s\n",
                        "Wall time: 10.4 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "from nltk import ViterbiParser\n",
                "parser = ViterbiParser(grammar)\n",
                "for tree in parser.parse(tokenized_sentence):\n",
                "    print(tree)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: total: 156 ms\n",
                        "Wall time: 260 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "parser = nltk.InsideChartParser(grammar, beam_size=100)\n",
                "for tree in parser.parse(tokenized_sentence):\n",
                "    print(tree)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: total: 156 ms\n",
                        "Wall time: 226 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "parser = nltk.RandomChartParser(grammar, beam_size=100)\n",
                "for tree in parser.parse(tokenized_sentence):\n",
                "    print(tree)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": "slide"
                }
            },
            "source": [
                "## 4. Generating Sentences\n",
                "\n",
                "Grammars can be used to generate sentences as well. This is accomplished using `generate` method.\n",
                "read [here](http://www.nltk.org/api/nltk.parse.html#module-nltk.parse.generate)\n",
                "\n",
                "arguments it takes are the following `nltk.parse.generate.generate(grammar, start=None, depth=None, n=None)`:\n",
                "\n",
                "- grammar – The Grammar used to generate sentences.\n",
                "- start – The Nonterminal, which is and NLTK object, from which to start generate sentences.\n",
                "- depth – The maximal depth of the generated tree.\n",
                "- n – The maximum number of sentences to return."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {
                "scrolled": true,
                "slideshow": {
                    "slide_type": "fragment"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['the', 'man', 'saw', 'the', 'man']\n",
                        "['the', 'man', 'saw', 'the', 'telescope']\n",
                        "['the', 'man', 'saw', 'a', 'man']\n",
                        "['the', 'man', 'saw', 'a', 'telescope']\n",
                        "['the', 'man', 'saw', 'the', 'man', 'with', 'the', 'man']\n",
                        "['the', 'man', 'saw', 'the', 'man', 'with', 'the', 'telescope']\n",
                        "['the', 'man', 'saw', 'the', 'man', 'with', 'a', 'man']\n",
                        "['the', 'man', 'saw', 'the', 'man', 'with', 'a', 'telescope']\n",
                        "['the', 'man', 'saw', 'the', 'man', 'with', 'the', 'man', 'with', 'the', 'man']\n",
                        "['the', 'man', 'saw', 'the', 'man', 'with', 'the', 'man', 'with', 'the', 'telescope']\n"
                    ]
                }
            ],
            "source": [
                "from nltk.parse.generate import generate\n",
                "toy_grammar = nltk.PCFG.fromstring(weighted_rules)\n",
                "for sent in generate(toy_grammar, n=10):\n",
                "    print(sent)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 4.1 Generating sequences with PCFG\n",
                "To used the probabilities on the production rules while generating, you can write your function or there is this library in python called [PCFG](https://github.com/thomasbreydo/pcfg). \n",
                "```bash\n",
                "pip install pcfg\n",
                "```\n",
                "The PCFG is fully compatible with NLTK, meaning that it task the same input as for `nltk.PCFG`, but it is limited as the only parameter available is the number of sentences that you want to generate."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "a telescope saw the telescope\n",
                        "a telescope saw a man with a man with I\n",
                        "a man with the man with the telescope saw a man with the telescope\n",
                        "a telescope with a man with I saw a man\n",
                        "the man saw a man\n",
                        "I saw the telescope with a telescope with a man with a man with the telescope with a man\n",
                        "a telescope with a telescope with a telescope saw the telescope\n",
                        "the man saw a man with the telescope\n",
                        "a man saw the telescope\n",
                        "the man saw the telescope with the man\n"
                    ]
                }
            ],
            "source": [
                "from pcfg import PCFG\n",
                "toy_grammar = PCFG.fromstring(weighted_rules)\n",
                "for sent in toy_grammar.generate(10):\n",
                "    print(sent)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 4.2 Generating sequences with PCFG (New version)\n",
                "Recently, a student of the NLU course has released a modified version of the pcfg library implementing two missing features namely `start` and `depth`. You can find this [here](https://github.com/halixness/pcfg). \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluating Constituency Parsers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1. Comparing Trees"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Since _constituency parser_ outputs _constituents_, parser evaluation is essentially a comparison between constituents of the reference and the automatic (hypothesis) parse trees (of the test set). Since constituents are labeled (have _syntactic categories_), the evaluation can also compare the reference and the hypothesis labels.\n",
                "\n",
                "A constituent in a hypothesis parse tree is considered correct, if there is a constituent in a reference parse tree that has the same span and label. That is:\n",
                "\n",
                "- has the same starting point\n",
                "- has the same ending point\n",
                "- has the same non-terminal symbol"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Using this information we can compute precision and recall for the parser, as:\n",
                "\n",
                "$$ \\text{recall} = \\frac{\\text{\\# of correct constituents in hypothesis}}{\\text{\\# of constituents in reference}}$$\n",
                "\n",
                "$$ \\text{precision} = \\frac{\\text{\\# of correct constituents in hypothesis}}{\\text{\\# of constituents in hypothesis}}$$\n",
                "\n",
                "The $F_1$ metric is computed the usual way, as:\n",
                "\n",
                "$$F_1 = \\frac{2PR}{P+R}$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In case for the correct constituent counts we consider labels, we compute _labeled_ precision and recall. Otherwise, metrics are _unlabeled_ (i.e. we just consider the span not the label). "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2. PARSEVAL\n",
                "The evaluation method that implements this is known as **PARSEVAL** [(Black et al., 1991)](https://aclanthology.org/H91-1060/).\n",
                "\n",
                "The metric includes an algorithm from _caninicalization_ that removes grammar-specific information and allows comparing parsers with different grammars.\n",
                "\n",
                "The \"canonical\" implementation of **PARSEVAL** is known as [**EVALB**](https://nlp.cs.nyu.edu/evalb/)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Since constitents are essentially sub-trees of a sentence parse tree, while having the same label and start and end points, they might differ in their internal structure. \n",
                "\n",
                "e.g.: `((A B) C)` vs. `(A (B C))`\n",
                "\n",
                "Consequently, there is an additional metric in **PARSEVAL** that is used to account for this -- **cross-brackets** (since parse trees are represented using bracketed notation) -- which is a simple count of such cases per sentence.\n",
                "\n",
                "However, since `((A B) C)` and `(A (B C))` have different constituents, this is already reflected in precision and recall. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1. EVALB (PYTHON)\n",
                "There is no officially supported EVALB for python. However, there are few implementations available.\n",
                "The most easy to use it [PYEVALB](https://github.com/flyaway1217/PYEVALB).\n",
                "\n",
                "It is possible to compare two parse trees as the following:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {},
            "outputs": [],
            "source": [
                "#!pip install PYEVALB\n",
                "from PYEVALB import scorer as eval_scorer\n",
                "from PYEVALB import parser as eval_parser\n",
                "\n",
                "pt0 = \"(S (NP (PRON I)) (VP (V saw) (NP (Det the) (N man)) (PP (P with) (NP (Det a) (N telescope)))))\"\n",
                "pt1 = \"(S (NP (PRON I)) (VP (V saw) (NP (Det the) (N man) (PP (P with) (NP (Det a) (N telescope))))))\"\n",
                "\n",
                "pt0_tree = eval_parser.create_from_bracket_string(pt0)\n",
                "pt1_tree = eval_parser.create_from_bracket_string(pt1)\n",
                "\n",
                "s = eval_scorer.Scorer()\n",
                "result = s.score_trees(pt0_tree, pt1_tree)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "P: 0.83 R: 0.83\n"
                    ]
                }
            ],
            "source": [
                "print(\"P: {} R: {}\".format(round(result.prec, 2), round(result.recall, 2)))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Lab Exercise\n",
                "- Write two or more sentences of your choice.\n",
                "- Write a PCFG that models your sentences.\n",
                "- To validate your grammar, parse the sentences with a parser of your choice.\n",
                "- Then, generate 10 sentences  using a PCFG by experimenting with `nltk.parse.generate.generate` using different starting symbols and depths. Optionally, generate 10 sentences with PCFG.generate() (see section 4)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk\n",
                "from nltk.parse.generate import generate\n",
                "\n",
                "test_sents = [\"I grab the hand of a star\", \"You saw a man on a castle\"]\n",
                "\n",
                "weighted_rules = [\n",
                "    'S -> NP VP [1.0]',\n",
                "    'NP -> Det N [0.4] | Det N PP [0.4] | PRON [0.2]',\n",
                "    'VP -> V NP [0.7] | V NP PP [0.3]',\n",
                "    'PP -> P NP [1.0]',\n",
                "    'Det -> \"the\" [0.2] | \"a\" [0.8]',\n",
                "    'N -> \"star\" [0.2] | \"castle\" [0.2] | \"hand\" [0.2] | \"man\" [0.4]',\n",
                "    'PRON -> \"I\" [0.5] | \"You\" [0.5]',\n",
                "    'V -> \"saw\" [0.5] | \"grab\" [0.5]',\n",
                "    'P -> \"of\" [0.5] | \"on\" [0.5]'\n",
                "]\n",
                "\n",
                "my_grammar = nltk.PCFG.fromstring(weighted_rules)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1\n",
                        "1\n"
                    ]
                }
            ],
            "source": [
                "from nltk.parse.generate import generate\n",
                "parser = nltk.ViterbiParser(my_grammar)\n",
                "for sent in test_sents:\n",
                "  parses = parser.parse(sent.split())\n",
                "  print(len(list(parses)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['the', 'star', 'saw', 'the', 'star']\n",
                        "['the', 'star', 'saw', 'the', 'castle']\n",
                        "['the', 'star', 'saw', 'the', 'hand']\n",
                        "['the', 'star', 'saw', 'the', 'man']\n",
                        "['the', 'star', 'saw', 'a', 'star']\n",
                        "['the', 'star', 'saw', 'a', 'castle']\n",
                        "['the', 'star', 'saw', 'a', 'hand']\n",
                        "['the', 'star', 'saw', 'a', 'man']\n",
                        "['the', 'star', 'saw', 'the', 'star', 'of', 'the', 'star']\n",
                        "['the', 'star', 'saw', 'the', 'star', 'of', 'the', 'castle']\n"
                    ]
                }
            ],
            "source": [
                "from nltk.parse.generate import generate\n",
                "from nltk import Nonterminal\n",
                "\n",
                "start = Nonterminal('S')\n",
                "for sent in generate(my_grammar, start=start, n=10):\n",
                "    print(sent)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
